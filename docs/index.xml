<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Consistent Bayes on Measure Theory in Action</title>
    <link>localhost:1313/</link>
    <description>Recent content in Consistent Bayes on Measure Theory in Action</description>
    <generator>Hugo -- gohugo.io</generator>
    
	<atom:link href="localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Disintegration Theorem</title>
      <link>localhost:1313/framework/disintegration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/framework/disintegration/</guid>
      <description>The Disintegration Theorem This is the powerhouse of the Measure-Theoretic framework It is leveraged to describe the probability of sets within contours, allowing for a unique solution to the stochastic inverse problem</description>
    </item>
    
    <item>
      <title>The Set Up</title>
      <link>localhost:1313/examples/setup/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/examples/setup/</guid>
      <description>Defining the Problem $$Q(\lambda)= \frac{1}{M} \sum_{i=1}^M \left(\frac{O_i(\lambda)-d_i}{\sigma_i}\right)^2$$     The distribution of $Q(\lambda)$&amp;rsquo;s should follow a gamma random variable with shape and rate parameters $M/2$:
$$\pi_{\mathcal{D}}(q) = \frac{(M/2)^{M/2}}{\Gamma(M/2)} q^{M/2-1}e^{-Mq/2}$$    
Note that the form of $\pi_{\mathcal{D}}(q)$ is independent of the actual time series of data that is observed.</description>
    </item>
    
    <item>
      <title>Experiment 1</title>
      <link>localhost:1313/examples/identity/luckyexperiment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/examples/identity/luckyexperiment/</guid>
      <description>Getting Lucky    -- Please allow a moment for the animation to load.</description>
    </item>
    
    <item>
      <title>Identify the Contour</title>
      <link>localhost:1313/framework/level1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/framework/level1/</guid>
      <description>   </description>
    </item>
    
    <item>
      <title>Inverting a Point</title>
      <link>localhost:1313/measuretheory/inverse/level1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/measuretheory/inverse/level1/</guid>
      <description>      </description>
    </item>
    
    <item>
      <title>Mapping a Point</title>
      <link>localhost:1313/measuretheory/forward/level1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/measuretheory/forward/level1/</guid>
      <description>   </description>
    </item>
    
    <item>
      <title>Prior Predictive</title>
      <link>localhost:1313/examples/expdecay/exp/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/examples/expdecay/exp/</guid>
      <description> Example: Exponential Decay   </description>
    </item>
    
    <item>
      <title>Prior Predictive</title>
      <link>localhost:1313/examples/harmosc/harm/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/examples/harmosc/harm/</guid>
      <description> Example: Harmonic Oscillator   </description>
    </item>
    
    <item>
      <title>Vector-Valued</title>
      <link>localhost:1313/intro/heatplate/vector-valued/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/intro/heatplate/vector-valued/</guid>
      <description>Vector-Valued Maps We can treat each measurement individually.   We refer to the QoI map induced by this treatment as being vector-valued.</description>
    </item>
    
    <item>
      <title>A Single Datum</title>
      <link>localhost:1313/problem/single/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/problem/single/</guid>
      <description>A Single Datum A Distribution Does Not Make   The wrong distribution can be imposed if we center our uncertainty on just one observation.</description>
    </item>
    
    <item>
      <title>Define Indexing Set</title>
      <link>localhost:1313/framework/level2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/framework/level2/</guid>
      <description>   </description>
    </item>
    
    <item>
      <title>Experiment 2</title>
      <link>localhost:1313/examples/identity/unluckyexperiment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/examples/identity/unluckyexperiment/</guid>
      <description>Less Fortunate     --
Please allow a moment for the animation to load.</description>
    </item>
    
    <item>
      <title>Inverting a Set</title>
      <link>localhost:1313/measuretheory/inverse/level2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/measuretheory/inverse/level2/</guid>
      <description>   </description>
    </item>
    
    <item>
      <title>Mapping a Set</title>
      <link>localhost:1313/measuretheory/forward/level2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/measuretheory/forward/level2/</guid>
      <description>   </description>
    </item>
    
    <item>
      <title>Posterior Predictive</title>
      <link>localhost:1313/examples/expdecay/exp_solve/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/examples/expdecay/exp_solve/</guid>
      <description> Example: Exponential Decay   </description>
    </item>
    
    <item>
      <title>Posterior Predictive</title>
      <link>localhost:1313/examples/harmosc/harm_solve/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/examples/harmosc/harm_solve/</guid>
      <description> Example: Harmonic Oscillator   </description>
    </item>
    
    <item>
      <title>Scalar-Valued</title>
      <link>localhost:1313/intro/heatplate/scalar-valued/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/intro/heatplate/scalar-valued/</guid>
      <description>Scalar-Valued Maps We can combine the information in some way into a single value.   We refer to the QoI map induced by this treatment as being scalar-valued.</description>
    </item>
    
    <item>
      <title>Inverting a Distribution</title>
      <link>localhost:1313/measuretheory/inverse/level3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/measuretheory/inverse/level3/</guid>
      <description>   </description>
    </item>
    
    <item>
      <title>Map onto Manifold</title>
      <link>localhost:1313/framework/level3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/framework/level3/</guid>
      <description>{   </description>
    </item>
    
    <item>
      <title>Mapping a Distribution</title>
      <link>localhost:1313/measuretheory/forward/level3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/measuretheory/forward/level3/</guid>
      <description>   </description>
    </item>
    
    <item>
      <title>Repeated Trials</title>
      <link>localhost:1313/problem/repeated/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/problem/repeated/</guid>
      <description> Better estimates of the distribution&amp;rsquo;s center arise from averaging over more data.    $$Q(\lambda)= \frac{1}{M} \sum_{j=1}^{M}O_j$$    
This is how we can improve the vector-valued posterior density. </description>
    </item>
    
    <item>
      <title>The Objective</title>
      <link>localhost:1313/intro/heatplate/objective/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/intro/heatplate/objective/</guid>
      <description>What we&amp;rsquo;re after We want to infer the values of \(\lambda_1\)    and \(\lambda_2\)   . We want to quantify the uncertainty in our parameters.

How do we use the information from our sensors to do this?</description>
    </item>
    
    <item>
      <title>Assimilation</title>
      <link>localhost:1313/problem/scalarizing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/problem/scalarizing/</guid>
      <description> Repeated Trials We could instead define a misfit function as our QoI instead. This effectively turns our QoI into a scalar-valued map. \(\newcommand{\lam}{(\lambda)}\)    \(\newcommand{\qoi}{Q\lam}\)    $$\qoi = \frac{1}{M} \sum_{i=1}^M \left(\frac{O_i\lam-d_i}{\sigma_i}\right)^2$$    
This represents our average deviation from the data.

What are the differences? </description>
    </item>
    
    <item>
      <title>Optimal Experimental Design</title>
      <link>localhost:1313/examples/harmosc/harm_summary/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/examples/harmosc/harm_summary/</guid>
      <description> How the Experiment is Performed Matters   </description>
    </item>
    
    <item>
      <title>Posterior</title>
      <link>localhost:1313/framework/post/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/framework/post/</guid>
      <description> A novel measure-theoretic framework Our posterior distribution is given by:
$$\pi^{\dagger}_\Lambda(\lambda) := \pi_\Lambda(\lambda)\frac{\pi_{\mathcal{D}}(Q(\lambda))}{\pi^{Q}_{\mathcal{D}}(Q(\lambda))} $$     </description>
    </item>
    
    <item>
      <title>Prior</title>
      <link>localhost:1313/framework/prior/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/framework/prior/</guid>
      <description>A novel measure-theoretic framework $$\pi^{\dagger}_\Lambda(\lambda) := \pi_\Lambda(\lambda)\frac{\pi_{\mathcal{D}}(Q(\lambda))}{\pi^{Q}_{\mathcal{D}}(Q(\lambda))} $$     
We use Bayes&amp;rsquo; Rule along contours.
The prior \(\pi_\Lambda(\lambda)\)    plays a role only in these directions.
It differentiates among sets that belong to the same contour $\sigma$-algebra.</description>
    </item>
    
    <item>
      <title>Observed</title>
      <link>localhost:1313/framework/observed/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/framework/observed/</guid>
      <description>A novel measure-theoretic framework $$\pi^{\dagger}_\Lambda(\lambda) := \pi_\Lambda(\lambda)\frac{\pi_{\mathcal{D}}(Q(\lambda))}{\pi^{Q}_{\mathcal{D}}(Q(\lambda))} $$     Across contours, we invert $$\pi_{\mathcal{D}}(Q(\lambda)).$$    
The term \(\pi^{Q}_{\mathcal{D}}(Q(\lambda))\)    is called the push-forward measure of the prior.
Characterizing this measure is unique to our approach for solving stochastic inverse problems.</description>
    </item>
    
    <item>
      <title>Future Work</title>
      <link>localhost:1313/conclusion/questions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>localhost:1313/conclusion/questions/</guid>
      <description>Future Work How much information is gained from measurement regimes? How to define QoI under non-Gaussian assumptions? How can we set up optimal experimental designs? Sensitivity Analysis (in progress)</description>
    </item>
    
  </channel>
</rss>